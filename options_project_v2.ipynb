{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Options Pricing\n",
    "For our final project, we will be visualizing how Monte Carlo simulations are used to price options.\n",
    "\n",
    "We'll begin with some explanations. Options are a financial contract that give the buyer the *right* (but not the obligation! hence the name \"option\") to buy or sell an asset at a specific price, the **strike price**, before the option's **expiration date**. There are two main kinds of options: **call options**, which let you buy an asset at the strike price before the expiration date, and **put options**, which let you sell an asset at the strike price before the expiration date.\n",
    "\n",
    "For example, let's say you want to buy a call option with a strike price of $110 that expires in 1 month on Pepsi stock, which is currently worth $100. How would you price this option? If you pay $10 for the option, you are hoping that Pepsi stock will be worth more than $110 in 1 month, so that you can buy it at $110 and sell it for more than you paid for the option.\n",
    "\n",
    "Say we buy this option for $10. If Pepsi stock goes up to $135 in 1 month, you can use the option to buy it at $110 and then sell it for $135, netting you a profit of $135 (what you sell it for) - $110 (the strike price you buy at) - $10 (the price of the option) = $15. You can see that the option is now worth $15, so it is a good deal!\n",
    "\n",
    "However, assume that Pepsi stock goes down to $90 in 1 month. If you bought the option, you would not use it, because you could just buy Pepsi stock for $90 - there's no reason to buy it at the option's strike price of $110. In this case, the option is worthless, and you would have lost the $10 you paid for it.\n",
    "\n",
    "Therefore, when buying an option, we seek to only buy it if we think that *on average* the option will return a profit above the price of buying it.\n",
    "\n",
    "<!-- TODO: Should this be a visualization of how this can go? -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Simulation with Metropolis-Hastings\n",
    "\n",
    "TODO: Make it less jargon-y\n",
    "\n",
    "In our Pepsi example, it's easy to see that the option is worth $15, so we should buy it. However, in the real world, we don't know the exact value of the option. Instead, we can use a Monte Carlo simulation to estimate the value of the option.\n",
    "\n",
    "Let's start with a simple coin tossing example to demonstrate how a Monte Carlo simulation works.\n",
    "\n",
    "Say we have a coin that has an unknown probability $p$ of landing heads. An intuitive way to estimate $p$ is to flip the coin many times and take the average of the number of heads. At its core, this is what a Monte Carlo simulation does: it repeatedly draws random samples from a probability distribution and then takes the average of the function evaluated at those samples.\n",
    "\n",
    "Let's demonstrate this now using code. For demonstration purposes, we'll begin by randomly generating a probability $p$ of landing heads, between 0 and 1 - in the real world, we wouldn't know what $p$ is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True probability p: 0.3773\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility.\n",
    "# np.random.seed(42)\n",
    "\n",
    "# Randomly generate the true probability of landing heads.\n",
    "true_p = np.random.uniform(0, 1)\n",
    "\n",
    "print(f\"True probability p: {true_p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we take this coin and toss it $N$ times, and count the number of heads and tails. This can be done using a Binomial distribution, which we simulate below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heads: 372 Tails: 628\n",
      "Empirical estimate of p: 0.3720\n",
      "True probability p: 0.3773\n"
     ]
    }
   ],
   "source": [
    "# Number of times to toss our coin.\n",
    "N = 1000\n",
    "\n",
    "# Define random variable and compute heads and tails\n",
    "coin_flips = np.random.binomial(1, true_p, size=N)\n",
    "num_heads = np.sum(coin_flips)\n",
    "num_tails = N - num_heads\n",
    "print(\"Heads:\", num_heads, \"Tails:\", num_tails)\n",
    "print(f\"Empirical estimate of p: {num_heads / N:.4f}\")\n",
    "print(f\"True probability p: {true_p:.4f}\")\n",
    "\n",
    "# Define target distribution:\n",
    "# Posterior alpha p^(num_heads) * (1 - p)^(num_tails), uniform prior\n",
    "def target(p):\n",
    "    if p <= 0 or p >= 1:\n",
    "        return 0\n",
    "    return (p ** num_heads) * ((1 - p) ** num_tails)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in this case we know the exact distribution of the coin – we can just flip it ourselves – so it's easy for us to compute the probability of heads. What if we didn't have the coin, or were dealing with a more complex set of variables? In this case, we can use something called the Metropolis-Hastings algorithm to estimate the probability of an event happening - in case of options, the probability of the stock price at expiration being above the strike price.\n",
    "\n",
    "To do this, we have to use something called rejection sampling. What this does is draw samples from a normal distribution, and then accept or reject those samples based on whether they are above or below the *target* distribution - what we expect the upper and lower bounds of the true distribution to be. For example, if we were to randomly draw a number greater than 1 from the normal distribution when trying to estimate the probability of heads, we would reject it, because we know the probability of heads being greater than 1 is 0.\n",
    "\n",
    "A visualization of this is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d1fb24ce14da4123917024011891f1cd.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d1fb24ce14da4123917024011891f1cd.vega-embed details,\n",
       "  #altair-viz-d1fb24ce14da4123917024011891f1cd.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d1fb24ce14da4123917024011891f1cd\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d1fb24ce14da4123917024011891f1cd\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d1fb24ce14da4123917024011891f1cd\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-3a3fac08a7e0bcd86b2269d6bbdf4792\"}, \"mark\": {\"type\": \"line\", \"color\": \"lightgray\", \"strokeWidth\": 1}, \"encoding\": {\"x\": {\"field\": \"Iteration\", \"title\": \"Iteration\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Chain Value\", \"scale\": {\"domain\": [0, 1]}, \"title\": \"Parameter Value\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-3a3fac08a7e0bcd86b2269d6bbdf4792\"}, \"mark\": {\"type\": \"line\", \"color\": \"blue\", \"strokeWidth\": 2}, \"encoding\": {\"x\": {\"field\": \"Iteration\", \"title\": \"Iteration\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Running Mean\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-8a2b748ab7dab6f2f6d4cb0cc956e991\"}, \"mark\": {\"type\": \"rule\", \"color\": \"red\", \"strokeWidth\": 2}, \"encoding\": {\"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}}], \"height\": 400, \"title\": \"Convergence of Estimated p (True p = 0.3773)\", \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-3a3fac08a7e0bcd86b2269d6bbdf4792\": [{\"Iteration\": 0, \"Chain Value\": 0.5, \"Running Mean\": 0.5}, {\"Iteration\": 1, \"Chain Value\": 0.5, \"Running Mean\": 0.5}, {\"Iteration\": 2, \"Chain Value\": 0.5, \"Running Mean\": 0.5}, {\"Iteration\": 3, \"Chain Value\": 0.5, \"Running Mean\": 0.5}, {\"Iteration\": 4, \"Chain Value\": 0.5, \"Running Mean\": 0.5}, {\"Iteration\": 5, \"Chain Value\": 0.5, \"Running Mean\": 0.5}, {\"Iteration\": 6, \"Chain Value\": 0.5, \"Running Mean\": 0.5}, {\"Iteration\": 7, \"Chain Value\": 0.5, \"Running Mean\": 0.5}, {\"Iteration\": 8, \"Chain Value\": 0.5, \"Running Mean\": 0.5}, {\"Iteration\": 9, \"Chain Value\": 0.5, \"Running Mean\": 0.5}, {\"Iteration\": 10, \"Chain Value\": 0.4227089873505632, \"Running Mean\": 0.49297354430459667}, {\"Iteration\": 11, \"Chain Value\": 0.3281795625606746, \"Running Mean\": 0.4792407124926032}, {\"Iteration\": 12, \"Chain Value\": 0.3281795625606746, \"Running Mean\": 0.467620624036301}, {\"Iteration\": 13, \"Chain Value\": 0.3281795625606746, \"Running Mean\": 0.45766054821661345}, {\"Iteration\": 14, \"Chain Value\": 0.3281795625606746, \"Running Mean\": 0.4490284825062175}, {\"Iteration\": 15, \"Chain Value\": 0.3281795625606746, \"Running Mean\": 0.4414754250096211}, {\"Iteration\": 16, \"Chain Value\": 0.3281795625606746, \"Running Mean\": 0.4348109625126243}, {\"Iteration\": 17, \"Chain Value\": 0.33560281735030184, \"Running Mean\": 0.42929939889249524}, {\"Iteration\": 18, \"Chain Value\": 0.33560281735030184, \"Running Mean\": 0.4243679998639588}, {\"Iteration\": 19, \"Chain Value\": 0.33560281735030184, \"Running Mean\": 0.419929740738276}, {\"Iteration\": 20, \"Chain Value\": 0.33560281735030184, \"Running Mean\": 0.41591417295789634}, {\"Iteration\": 21, \"Chain Value\": 0.33560281735030184, \"Running Mean\": 0.4122636567939148}, {\"Iteration\": 22, \"Chain Value\": 0.33560281735030184, \"Running Mean\": 0.4089305768181056}, {\"Iteration\": 23, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.40738595664410826}, {\"Iteration\": 24, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.40596490608403074}, {\"Iteration\": 25, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.40465316710549765}, {\"Iteration\": 26, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.40343859397722626}, {\"Iteration\": 27, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.4023107760724028}, {\"Iteration\": 28, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.4012607387127396}, {\"Iteration\": 29, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.4002807038437206}, {\"Iteration\": 30, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.39936389703076736}, {\"Iteration\": 31, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.3985043906436237}, {\"Iteration\": 32, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.39769697555267053}, {\"Iteration\": 33, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.3969370554670676}, {\"Iteration\": 34, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.39622055938635625}, {\"Iteration\": 35, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.3955438686434622}, {\"Iteration\": 36, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.3949037557785624}, {\"Iteration\": 37, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.3942973330644468}, {\"Iteration\": 38, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.3937220089510551}, {\"Iteration\": 39, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.39317545104333296}, {\"Iteration\": 40, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.39265555449696316}, {\"Iteration\": 41, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.3921604149289919}, {\"Iteration\": 42, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.39168830510836816}, {\"Iteration\": 43, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.3912376548250455}, {\"Iteration\": 44, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.3908070334432039}, {\"Iteration\": 45, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.390395134730138}, {\"Iteration\": 46, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.3900007636218834}, {\"Iteration\": 47, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.3896228246431394}, {\"Iteration\": 48, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.38926031174516046}, {\"Iteration\": 49, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.3889122993631007}, {\"Iteration\": 50, \"Chain Value\": 0.37185969264217034, \"Running Mean\": 0.38857793452543543}, {\"Iteration\": 51, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3878430411504665}, {\"Iteration\": 52, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3871358796009681}, {\"Iteration\": 53, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.38645490921996967}, {\"Iteration\": 54, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.38579870139828026}, {\"Iteration\": 55, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.38516592957022266}, {\"Iteration\": 56, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.38455536026244774}, {\"Iteration\": 57, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.38396584506873405}, {\"Iteration\": 58, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3833963134409089}, {\"Iteration\": 59, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.38284576620067795}, {\"Iteration\": 60, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3823132696896349}, {\"Iteration\": 61, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3817979504853997}, {\"Iteration\": 62, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3812989906209815}, {\"Iteration\": 63, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3808156232523264}, {\"Iteration\": 64, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3803471287257837}, {\"Iteration\": 65, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.37989283100307564}, {\"Iteration\": 66, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3794520944064186}, {\"Iteration\": 67, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3790243206508397}, {\"Iteration\": 68, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3786089461345529}, {\"Iteration\": 69, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.37820543946158863}, {\"Iteration\": 70, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.37781329917377826}, {\"Iteration\": 71, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3774320516717404}, {\"Iteration\": 72, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3770612493067447}, {\"Iteration\": 73, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.37670046862728934}, {\"Iteration\": 74, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.37634930876595285}, {\"Iteration\": 75, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.3760073899535989}, {\"Iteration\": 76, \"Chain Value\": 0.35036347902705356, \"Running Mean\": 0.37567435214935807}, {\"Iteration\": 77, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.3752443499598754}, {\"Iteration\": 78, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.3748252339017721}, {\"Iteration\": 79, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.3744165957451213}, {\"Iteration\": 80, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.37401804741949896}, {\"Iteration\": 81, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.3736292197847455}, {\"Iteration\": 82, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.37324976149058847}, {\"Iteration\": 83, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.3728793379177209}, {\"Iteration\": 84, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.37251763019362666}, {\"Iteration\": 85, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.3721643342770695}, {\"Iteration\": 86, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.3718191601057205}, {\"Iteration\": 87, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.37148183080190217}, {\"Iteration\": 88, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.37115208193187754}, {\"Iteration\": 89, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.3708296608145201}, {\"Iteration\": 90, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.37051432587556615}, {\"Iteration\": 91, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.3702058460439807}, {\"Iteration\": 92, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.3699040001872681}, {\"Iteration\": 93, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.369608576582826}, {\"Iteration\": 94, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.3693193724226879}, {\"Iteration\": 95, \"Chain Value\": 0.34213418136971135, \"Running Mean\": 0.3690361933492194}, {\"Iteration\": 96, \"Chain Value\": 0.34107278691492926, \"Running Mean\": 0.36874791080865965}, {\"Iteration\": 97, \"Chain Value\": 0.34107278691492926, \"Running Mean\": 0.36846551158525426}, {\"Iteration\": 98, \"Chain Value\": 0.34107278691492926, \"Running Mean\": 0.3681888173966651}, {\"Iteration\": 99, \"Chain Value\": 0.34107278691492926, \"Running Mean\": 0.3679176570918477}], \"data-8a2b748ab7dab6f2f6d4cb0cc956e991\": [{\"y\": 0.377275973796942}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Apply Metropolis-Hastings algorithm.\n",
    "# TODO: Turn into function.\n",
    "# TODO: Add sliders for the visualization to make it interactive.\n",
    "num_iterations = 100\n",
    "proposal_std = 0.5  # Increase to allow broader exploration\n",
    "chain = []\n",
    "\n",
    "current_p = 0.5  # Starting guess\n",
    "for i in range(num_iterations):\n",
    "    proposed_p = current_p + np.random.normal(0, proposal_std)\n",
    "    # Ensure candidate remains in [0, 1]\n",
    "    proposed_p = np.clip(proposed_p, 0, 1)\n",
    "\n",
    "    current_target = target(current_p)\n",
    "    proposed_target = target(proposed_p)\n",
    "\n",
    "    # If current_target == 0, accept if proposed_target > 0, else 0\n",
    "    if current_target == 0:\n",
    "        acceptance_prob = 1 if proposed_target > 0 else 0\n",
    "    else:\n",
    "        acceptance_prob = min(1, proposed_target / current_target)\n",
    "\n",
    "    if np.random.rand() < acceptance_prob:\n",
    "        current_p = proposed_p\n",
    "\n",
    "    chain.append(current_p)\n",
    "\n",
    "chain = np.array(chain)\n",
    "\n",
    "# Compute running mean at each step\n",
    "# TODO: Visualize this as a stochastic process, i.e. an animation of some kind.\n",
    "running_mean = np.cumsum(chain) / (np.arange(num_iterations) + 1)\n",
    "\n",
    "# Prepare DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Iteration': np.arange(num_iterations),\n",
    "    'Chain Value': chain,\n",
    "    'Running Mean': running_mean\n",
    "})\n",
    "\n",
    "# TODO: Turn into function as well\n",
    "# Altair visualization of the data.\n",
    "# Gray line for raw chain, including rejections\n",
    "base = alt.Chart(df).encode(\n",
    "    x=alt.X('Iteration:Q', title='Iteration')\n",
    ")\n",
    "\n",
    "chain_line = base.mark_line(\n",
    "    color='lightgray',\n",
    "    strokeWidth=1\n",
    ").encode(\n",
    "    y=alt.Y('Chain Value:Q', \n",
    "            title='Parameter Value',\n",
    "            scale=alt.Scale(domain=[0, 1]))  # Force y-axis [0,1]\n",
    ")\n",
    "\n",
    "# Blue line to track running mean\n",
    "running_mean_line = base.mark_line(\n",
    "    color='blue',\n",
    "    strokeWidth=2\n",
    ").encode(\n",
    "    y='Running Mean:Q'\n",
    ")\n",
    "\n",
    "# Red horizontal rule for the true probability of the coin\n",
    "true_rule = alt.Chart(pd.DataFrame({'y': [true_p]})).mark_rule(\n",
    "    color='red',\n",
    "    strokeWidth=2\n",
    ").encode(\n",
    "    y='y:Q'\n",
    ")\n",
    "\n",
    "# Combine all the layers together\n",
    "final_chart = alt.layer(\n",
    "    chain_line,\n",
    "    running_mean_line,\n",
    "    true_rule\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400,\n",
    "    title=f'Convergence of Estimated p (True p = {true_p:.4f})'\n",
    ")\n",
    "\n",
    "final_chart.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Introduce notion of \"burnout\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Introduce Monte Carlo simulation of *expected* value of the option, not just the probability it will return a profit or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Gradually introduce different variables for the user to interact with: number of path simulations, number of iterations, volatility, strike price, drift, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
